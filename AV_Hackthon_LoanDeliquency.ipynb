{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data into environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('D:\\\\DataScience\\\\AV_HackThon\\\\train.csv')\n",
    "test=pd.read_csv('D:\\\\DataScience\\\\AV_HackThon\\\\test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()\n",
    "# print ('train shape',train.shape)\n",
    "# print('test shape',test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine train and test variables into combined dataset so that, we can do feature extractions and feature transformations together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols =[col for col in train.columns if train[col].dtype=='object']\n",
    "obj_cols\n",
    "\n",
    "# test['origination_date'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "except origination and first payment date other columns are not required, hence dropping them from the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_cols =list(set(obj_cols) - set(['source',\n",
    " 'financial_institution','loan_purpose']))\n",
    "obj_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# test['first_payment_date'].strftime(\"%d-%m-%Y\")\n",
    " \n",
    "test['first_payment_date']=test['first_payment_date'].apply(lambda x: datetime.strptime(x,\"%b-%y\"))\n",
    "train['first_payment_date']=train['first_payment_date'].apply(lambda x: datetime.strptime(x,\"%m/%Y\"))\n",
    "test['origination_date']=test['origination_date'].apply(lambda x: datetime.strptime(x,\"%d/%m/%y\"))\n",
    "train['origination_date']=train['origination_date'].apply(lambda x: datetime.strptime(x,\"%Y-%m-%d\"))\n",
    "\n",
    "train['origination_date']=train['origination_date'].apply(lambda x: x.strftime(\"%d-%m-%Y\"))\n",
    "test['origination_date']=test['origination_date'].apply(lambda x: x.strftime(\"%d-%m-%Y\"))\n",
    "train['first_payment_date']=train['first_payment_date'].apply(lambda x: x.strftime(\"%d-%m-%Y\"))\n",
    "test['first_payment_date']=test['first_payment_date'].apply(lambda x: x.strftime(\"%d-%m-%Y\"))\n",
    "\n",
    "\n",
    "# test['origination_date'].apply(lambda x: datetime.strptime(x,\"%d/%m/%y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['origination_date'].unique())\n",
    "print(train['first_payment_date'].unique())\n",
    "print(test['first_payment_date'].unique())\n",
    "print(test['origination_date'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see from above cell, the unique values are less so it is better to use one hot encoding for these variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_cols_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one hot encoding for origination_date and first_payment_dateb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Use as many lines of code as you need!\n",
    "onehotencoder=OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "OH_cols_train  =pd.DataFrame(onehotencoder.fit_transform(train[obj_cols]))\n",
    "OH_cols_valid = pd.DataFrame(onehotencoder.transform(test[obj_cols]))\n",
    "\n",
    "OH_cols_train .index=train.index\n",
    "OH_cols_valid.index=test.index\n",
    "\n",
    "num_cols_train=[col for col in train.columns if train[col].dtype != 'object']\n",
    "num_cols_test=[col for col in test.columns if test[col].dtype != 'object']\n",
    "\n",
    "# loan id can't be using in trianing\n",
    "num_cols_train.remove('loan_id') \n",
    "num_cols_test.remove('loan_id')\n",
    "\n",
    "num_train=train[num_cols_train]\n",
    "num_test=test[num_cols_test]\n",
    "\n",
    "OH_train=pd.concat([num_train,OH_cols_train],axis=1)\n",
    "OH_test=pd.concat([num_test,OH_cols_valid],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.barplot(train['interest_rate'].round(),train['m13'],hue=train['number_of_borrowers'],ci=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliquency_cols2=['m1','m2','m3','m4','m5','m6','m7','m8','m9','m10','m11','m12','m13']\n",
    "deliquency_cols=['m1','m2','m3','m4','m5','m6','m7','m8','m9','m10','m11','m12']\n",
    "\n",
    "\n",
    "# test['m']=test[deliquency_cols].sum(axis=1)\n",
    "# test.head()\n",
    "\n",
    "# test['m13']=test['m'].apply(lambda x: 1 if x>0 else 0 )\n",
    "\n",
    "# test[['loan_id','m13']].to_csv('submission.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_train['m']=OH_train[deliquency_cols].sum(axis=1)\n",
    "Last3_cols=['m10','m11','m12']\n",
    "Last6_cols=['m9','m7','m8','m10','m11','m12']\n",
    "\n",
    "OH_train['Last3']=OH_train[Last3_cols].sum(axis=1)\n",
    "OH_train['Last6']=OH_train[Last6_cols].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_test['m']=OH_test[deliquency_cols].sum(axis=1)\n",
    "OH_test['Last3']=OH_test[Last3_cols].sum(axis=1)\n",
    "OH_test['Last6']=OH_test[Last6_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_test['credit_score']=OH_test['borrower_credit_score']+OH_test['co-borrower_credit_score']\n",
    "OH_train['credit_score']=OH_train['borrower_credit_score']+OH_train['co-borrower_credit_score']\n",
    "\n",
    "OH_test.drop(columns=['borrower_credit_score','co-borrower_credit_score'],inplace=True)\n",
    "OH_train.drop(columns=['borrower_credit_score','co-borrower_credit_score'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deliquency_cols=['m1','m2','m3','m4','m5','m6','m7','m8','m9','m10','m11','m12']\n",
    "# OH_train['m']=OH_train[deliquency_cols].sum(axis=1)\n",
    "# OH_test['m']=OH_test[deliquency_cols].sum(axis=1)\n",
    "\n",
    "OH_test.drop(columns=deliquency_cols,inplace=True)\n",
    "OH_train.drop(columns=deliquency_cols,inplace=True)\n",
    "print(OH_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cols=list(OH_train.columns)\n",
    "cols.remove('m13')\n",
    "X=OH_train.loc[:,cols]\n",
    "y=OH_train.loc[:,'m13']\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OH_train.groupby('m13').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you see from above the output cell, this dataset is heavily imbalance, class 1 is undersampled, lets use some sampling methods to fix this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "X= pd.concat([X_train,y_train],axis=1)\n",
    "\n",
    "default= X[X.m13==1]\n",
    "no_default= X[X.m13==0]\n",
    "no_default.reset_index(inplace=True)\n",
    "print('count of default class',default.shape)\n",
    "print('count of no default class',no_default.shape)\n",
    "\n",
    "\n",
    "#up sample default class\n",
    "default_upsampled=resample(default,replace=True,n_samples=len(no_default),random_state=10)\n",
    "default_upsampled.reset_index(inplace=True)\n",
    "default_upsampled.index\n",
    "\n",
    "upsampled=pd.concat([default_upsampled,no_default],axis=0,ignore_index=True)\n",
    "\n",
    "upsampled.shape\n",
    "\n",
    "y_train=upsampled.m13\n",
    "X_train=upsampled.drop(columns=['m13'])\n",
    "X_train=X_train.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## under sample the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X= pd.concat([X_train,y_train],axis=1)\n",
    "\n",
    "default= X[X.m13==1]\n",
    "no_default= X[X.m13==0]\n",
    "no_default.reset_index(inplace=True)\n",
    "\n",
    "#up sample default class\n",
    "no_default_undersample=resample(no_default,replace=True,n_samples=len(default),random_state=10)\n",
    "undersampled=pd.concat([default,no_default_undersample],axis=0,ignore_index=True)\n",
    "\n",
    "print('sample size',undersampled.shape)\n",
    "\n",
    "y_train=undersampled.m13\n",
    "X_train=undersampled.drop(columns=['m13'])\n",
    "X_train=X_train.drop(columns=['index'])\n",
    "\n",
    "print('y_train shape',y_train.shape)\n",
    "print('x_train shape',X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE : over sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=0) # recreate the train and test datasets\n",
    "\n",
    "sm=SMOTE(random_state=12,ratio=1.0)\n",
    "X_train_sm,y_train_sm=sm.fit_sample(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train=undersampled.m13\n",
    "# undersampled.drop(columns=['m13','index'],inplace=True)\n",
    "# X_train=undersampled.drop(columns=['m13'])\n",
    "# X_train=X_train.drop(columns=['index'],inplace=True)\n",
    "X_train=undersampled.copy()\n",
    "X_train=X_train[cols]\n",
    "y_train.head()\n",
    "print(X_train.columns)\n",
    "print(X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(model):\n",
    "    model.fit(X_train,y_train)\n",
    "    predict_test=model.predict(X_test)\n",
    "    model_score=f1_score(y_test,predict_test)\n",
    "    print('F1 score is ',f1_score(y_test,predict_test))\n",
    "    \n",
    "    return model_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_submit(model):\n",
    "    predict_test=model.predict(OH_test.loc[:,cols])\n",
    "    test['m13']=predict_test\n",
    "    test.loc[:,['loan_id','m13']].to_csv('submission.csv',index=False)\n",
    "    print('sumbmission file created')\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "\n",
    "model_naiveBayes=MultinomialNB()\n",
    "model_dt=DecisionTreeClassifier()\n",
    "model_lr=LogisticRegression()\n",
    "model_knn=KNeighborsClassifier(n_neighbors=10)\n",
    "model_svm=SVC(kernel='linear',C=0.025,random_state=9)\n",
    "model_RF=RandomForestClassifier()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('leniar Regression',model_accuracy(model_lr))\n",
    "# print('KNN Regression',model_accuracy(model_knn))\n",
    "print('SVM Regression',model_accuracy(model_svm))\n",
    "# print(X_train.shape)\n",
    "# print('random Forest',model_accuracy(model_RF))\n",
    "# to_submit(model_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":\"reg:logistic\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10,'n_esitmators':100}\n",
    "\n",
    "model_RF=xgb.XGBClassifier(missing=9999999999,\n",
    "                objective='reg:logistic',\n",
    "                max_depth =20,\n",
    "                n_estimators=70,\n",
    "                learning_rate=0.001, \n",
    "                nthread=5,\n",
    "                subsample=1.0,\n",
    "                colsample_bytree=0.7,\n",
    "                min_child_weight = 5,\n",
    "                importance_type='weight',\n",
    "                eta=0.05,\n",
    "                scale_pos_weight=1.70,\n",
    "                reg_lambda=1.2,\n",
    "                seed=1301)\n",
    "\n",
    "model_accuracy(model_RF)\n",
    "to_submit(model_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmtraix=xgb.DMatrix(X_train,y_train)\n",
    "\n",
    "params = {\"objective\":\"reg:logistic\",'colsample_bytree': 0.3,'learning_rate': 0.1,\n",
    "                'max_depth': 5, 'alpha': 10}\n",
    "cv_results = xgb.cv(dtrain=data_dmtraix, params=params, nfold=10,\n",
    "                    num_boost_round=50,early_stopping_rounds=10,metrics=['auc'], as_pandas=True, seed=123)\n",
    "cv_results\n",
    "# print((cv_results[\"test-rmse-mean\"]).tail(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier()\n",
    "print('Best number of trees = {}'.format(cv_results.shape[0]))\n",
    "xgb_model.set_params(n_estimators=cv_results.shape[0])\n",
    "print('Fit on the trainingsdata')\n",
    "xgb_model.fit(X_train, y_train, eval_metric='auc')\n",
    "print('Overall AUC:', metrics.roc_auc_score(y, xgb_model.predict_proba(X)[:,1]))\n",
    "print('Predict the probabilities based on features in the test set')\n",
    "pred = xgb_model.predict_proba(OH_test[cols], ntree_limit=cv_results.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_int = pred[:,1]>0.3\n",
    "pred_int\n",
    "\n",
    "submission = pd.DataFrame({\"loan_id\":test.loan_id, \"m13\":pred_int})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('NaiveBayes Score',model_accuracy(model_naiveBayes))\n",
    "# print('Randomforest Score',model_accuracy(model_RF))\n",
    "# print('Decision tree Score',model_accuracy(model_dt))\n",
    "# print('Randomforest Score',model_accuracy(xgb_model))\n",
    "\n",
    "to_submit(xgb_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
